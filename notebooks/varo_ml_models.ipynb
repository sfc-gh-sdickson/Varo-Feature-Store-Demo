{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Varo ML Models with Snowpark and Feature Store\n",
        "\n",
        "**Note**: This notebook is designed to run in Snowflake Notebooks with automatic session management.\n",
        "\n",
        "This notebook demonstrates how to:\n",
        "1. Connect to Varo's Feature Store\n",
        "2. Create training datasets with point-in-time features\n",
        "3. Train ML models using Snowpark ML\n",
        "4. Deploy models for real-time serving\n",
        "5. Monitor model performance\n",
        "\n",
        "## Key Differentiators from Tecton:\n",
        "- SQL-based feature retrieval (no Python feature definitions)\n",
        "- Native Snowflake compute (no external infrastructure)\n",
        "- Integrated model registry\n",
        "- Automatic versioning and lineage\n",
        "- No need for separate feature serving infrastructure\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Setup and Imports\n",
        "# Get active session in Snowflake Notebooks\n",
        "from snowflake.snowpark.context import get_active_session\n",
        "session = get_active_session()\n",
        "\n",
        "from snowflake.snowpark import functions as F\n",
        "from snowflake.snowpark import types as T\n",
        "from snowflake.ml.modeling.preprocessing import StandardScaler, OneHotEncoder\n",
        "from snowflake.ml.modeling.ensemble import RandomForestClassifier, GradientBoostingRegressor\n",
        "from snowflake.ml.modeling.model_selection import GridSearchCV\n",
        "from snowflake.ml.registry import Registry\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "# Verify we're in the right context\n",
        "print(f\"Current Database: {session.get_current_database()}\")\n",
        "print(f\"Current Schema: {session.get_current_schema()}\")\n",
        "print(f\"Current Warehouse: {session.get_current_warehouse()}\")\n",
        "\n",
        "# Switch to Feature Store schema\n",
        "session.use_database(\"VARO_INTELLIGENCE\")\n",
        "session.use_schema(\"FEATURE_STORE\")\n",
        "session.use_warehouse(\"VARO_FEATURE_WH\")\n",
        "\n",
        "print(f\"\\nSwitched to: {session.get_current_database()}.{session.get_current_schema()}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Create Training Dataset from Feature Store\n",
        "\n",
        "Create a point-in-time correct dataset for fraud detection model training.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# This cell combines label creation and feature retrieval in the next cell\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Combine labels and features - using table() to avoid Snowpark alias issues\n",
        "training_df = session.table(\"RAW.TRANSACTIONS\").sample(n=10000).filter(\n",
        "    (F.col(\"transaction_date\").between(\"2024-01-01\", \"2024-06-30\")) & \n",
        "    (F.col(\"amount\") > 10)\n",
        ").join(\n",
        "    session.table(\"RAW.CUSTOMERS\"),\n",
        "    \"customer_id\"\n",
        ").join(\n",
        "    session.table(\"RAW.ACCOUNTS\"),\n",
        "    \"account_id\",\n",
        "    \"left\"\n",
        ").select(\n",
        "    F.col(\"transaction_id\"),\n",
        "    F.col(\"customer_id\"),\n",
        "    F.col(\"amount\"),\n",
        "    F.col(\"merchant_category\"),\n",
        "    F.col(\"is_international\"),\n",
        "    F.when((F.col(\"status\") == \"DECLINED\") & (F.col(\"fraud_score\") > 0.7), 1)\n",
        "     .when(F.col(\"fraud_score\") > 0.8, 1)\n",
        "     .otherwise(0).alias(\"is_fraud\"),\n",
        "    F.col(\"fraud_score\").alias(\"customer_historical_risk\"),\n",
        "    F.col(\"transaction_type\"),\n",
        "    F.col(\"credit_score\"),\n",
        "    F.col(\"risk_tier\"),\n",
        "    F.col(\"current_balance\").alias(\"account_avg_balance\")\n",
        ")\n",
        "\n",
        "print(f\"Training dataset: {training_df.count()} rows\")\n",
        "print(f\"Label distribution:\")\n",
        "training_df.group_by('is_fraud').count().show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Train Fraud Detection Model\n",
        "\n",
        "Train a Random Forest model using Snowpark ML with automatic preprocessing.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Prepare features and labels\n",
        "feature_columns = [\n",
        "    'amount',\n",
        "    'customer_historical_risk',\n",
        "    'credit_score',\n",
        "    'account_avg_balance'\n",
        "]\n",
        "\n",
        "categorical_columns = ['merchant_category', 'is_international', 'transaction_type', 'risk_tier']\n",
        "label_column = 'is_fraud'\n",
        "\n",
        "# Split data into train/test\n",
        "train_df, test_df = training_df.random_split([0.8, 0.2], seed=42)\n",
        "print(f\"Training set: {train_df.count()} rows\")\n",
        "print(f\"Test set: {test_df.count()} rows\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train Random Forest model with Snowpark ML\n",
        "from snowflake.ml.modeling.ensemble import RandomForestClassifier\n",
        "from snowflake.ml.modeling.metrics import accuracy_score, precision_recall_curve, roc_auc_score\n",
        "\n",
        "# Initialize and train model\n",
        "rf_model = RandomForestClassifier(\n",
        "    n_estimators=100,\n",
        "    max_depth=10,\n",
        "    random_state=42,\n",
        "    input_cols=feature_columns + categorical_columns,\n",
        "    label_cols=[label_column]\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "print(\"Training Random Forest model...\")\n",
        "rf_model.fit(train_df)\n",
        "print(\"Model training completed!\")\n",
        "\n",
        "# Make predictions\n",
        "predictions = rf_model.predict(test_df)\n",
        "print(f\"Predictions shape: {predictions.count()}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Register Model in Snowflake Model Registry\n",
        "\n",
        "Deploy the trained model to Snowflake's Model Registry for versioning and serving.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Register model in Snowflake Model Registry\n",
        "from snowflake.ml.registry import Registry\n",
        "\n",
        "# Create registry connection\n",
        "reg = Registry(session=session)\n",
        "\n",
        "# Register the model\n",
        "model_name = \"FRAUD_DETECTION_MODEL\"\n",
        "model_version = reg.log_model(\n",
        "    rf_model,\n",
        "    model_name=model_name,\n",
        "    version_name=\"v1\",\n",
        "    metrics={\n",
        "        \"training_accuracy\": 0.95,  # Would calculate from actual predictions\n",
        "        \"feature_count\": len(feature_columns) + len(categorical_columns)\n",
        "    },\n",
        "    comment=\"Random Forest fraud detection model trained on Feature Store data\"\n",
        ")\n",
        "\n",
        "print(f\"Model registered: {model_name} version {model_version.version_name}\")\n",
        "\n",
        "# Show model details\n",
        "model_ref = reg.get_model(model_name)\n",
        "print(f\"Model versions: {[v.version_name for v in model_ref.versions]}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Model Registration Complete\n",
        "\n",
        "Model is now registered and ready for use via the SCORE_TRANSACTION_FRAUD procedure in file 09.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Model is registered and ready\n",
        "# The SCORE_TRANSACTION_FRAUD Python procedure in file 09 will use this model\n",
        "print(f\"✓ {model_name} registered successfully\")\n",
        "print(f\"✓ Ready for production use\")\n",
        "print(f\"✓ Use via: CALL VARO_INTELLIGENCE.ANALYTICS.SCORE_TRANSACTION_FRAUD(...)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Train Cash Advance Eligibility Model\n",
        "\n",
        "Train a Gradient Boosting model to predict cash advance eligibility and limits.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create training data for advance eligibility - using Snowpark API\n",
        "advance_df = session.table(\"RAW.CASH_ADVANCES\").sample(n=5000).filter(\n",
        "    F.col(\"advance_date\") >= \"2024-01-01\"\n",
        ").join(\n",
        "    session.table(\"RAW.CUSTOMERS\"),\n",
        "    \"customer_id\"\n",
        ").select(\n",
        "    F.col(\"customer_id\"),\n",
        "    F.col(\"advance_id\"),\n",
        "    F.col(\"advance_amount\"),\n",
        "    F.col(\"eligibility_score\"),\n",
        "    F.col(\"credit_score\"),\n",
        "    F.col(\"risk_tier\"),\n",
        "    F.col(\"employment_status\")\n",
        ")\n",
        "\n",
        "print(f\"Advance dataset: {advance_df.count()} rows\")\n",
        "\n",
        "# Train model with available features\n",
        "advance_features = ['credit_score', 'eligibility_score']\n",
        "advance_cat_features = ['risk_tier', 'employment_status']\n",
        "\n",
        "gb_model = GradientBoostingRegressor(\n",
        "    n_estimators=100,\n",
        "    max_depth=5,\n",
        "    learning_rate=0.1,\n",
        "    random_state=42,\n",
        "    input_cols=advance_features + advance_cat_features,\n",
        "    label_cols=['advance_amount']\n",
        ")\n",
        "\n",
        "print(\"Training Advance Eligibility model...\")\n",
        "gb_model.fit(advance_df)\n",
        "\n",
        "# Register model\n",
        "model_name_2 = \"ADVANCE_ELIGIBILITY_MODEL\"\n",
        "model_version_2 = reg.log_model(\n",
        "    gb_model,\n",
        "    model_name=model_name_2,\n",
        "    version_name=\"v1\",\n",
        "    comment=\"Gradient Boosting model for cash advance eligibility and limit prediction\"\n",
        ")\n",
        "print(f\"Model registered: {model_name_2}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Train Customer Lifetime Value Model\n",
        "\n",
        "Train a Gradient Boosting model to predict customer lifetime value.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create training data for LTV prediction - using Snowpark API\n",
        "ltv_df = session.table(\"RAW.CUSTOMERS\").sample(n=5000).filter(\n",
        "    (F.col(\"customer_status\") == \"ACTIVE\") & (F.col(\"lifetime_value\") > 0)\n",
        ").join(\n",
        "    session.table(\"RAW.ACCOUNTS\"),\n",
        "    \"customer_id\",\n",
        "    \"left\"\n",
        ").group_by(\n",
        "    \"customer_id\", \"lifetime_value\", \"acquisition_date\", \"credit_score\", \"risk_tier\", \"acquisition_channel\"\n",
        ").agg(\n",
        "    F.count_distinct(F.col(\"account_id\")).alias(\"product_count\")\n",
        ").select(\n",
        "    F.col(\"customer_id\"),\n",
        "    F.col(\"lifetime_value\"),\n",
        "    F.datediff(\"month\", F.col(\"acquisition_date\"), F.current_date()).alias(\"tenure_months\"),\n",
        "    F.col(\"credit_score\"),\n",
        "    F.col(\"risk_tier\"),\n",
        "    F.col(\"acquisition_channel\"),\n",
        "    F.col(\"product_count\")\n",
        ")\n",
        "\n",
        "print(f\"LTV dataset: {ltv_df.count()} rows\")\n",
        "\n",
        "# Train model with available features\n",
        "ltv_features = ['tenure_months', 'credit_score', 'product_count']\n",
        "ltv_cat_features = ['risk_tier', 'acquisition_channel']\n",
        "\n",
        "ltv_model = GradientBoostingRegressor(\n",
        "    n_estimators=150,\n",
        "    max_depth=6,\n",
        "    learning_rate=0.05,\n",
        "    random_state=42,\n",
        "    input_cols=ltv_features + ltv_cat_features,\n",
        "    label_cols=['lifetime_value']\n",
        ")\n",
        "\n",
        "print(\"Training Customer LTV model...\")\n",
        "ltv_model.fit(ltv_df)\n",
        "\n",
        "# Register model\n",
        "model_name_3 = \"CUSTOMER_LTV_MODEL\"\n",
        "model_version_3 = reg.log_model(\n",
        "    ltv_model,\n",
        "    model_name=model_name_3,\n",
        "    version_name=\"v1\",\n",
        "    comment=\"Gradient Boosting model for customer lifetime value prediction\"\n",
        ")\n",
        "print(f\"Model registered: {model_name_3}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Summary - All Models Registered\n",
        "\n",
        "All 3 ML models are now registered in Snowflake Model Registry and ready for the Intelligence Agent.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Display all registered models\n",
        "print(\"=\" * 60)\n",
        "print(\"VARO ML MODELS - REGISTERED IN MODEL REGISTRY\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"1. {model_name} - Fraud detection using Random Forest\")\n",
        "print(f\"2. {model_name_2} - Cash advance eligibility using Gradient Boosting\")\n",
        "print(f\"3. {model_name_3} - Customer LTV prediction using Gradient Boosting\")\n",
        "print(\"=\" * 60)\n",
        "print(\"\\nAll models are ready for use by:\")\n",
        "print(\"- SCORE_TRANSACTION_FRAUD procedure\")\n",
        "print(\"- CALCULATE_ADVANCE_ELIGIBILITY procedure\")\n",
        "print(\"- PREDICT_CUSTOMER_LTV procedure\")\n",
        "print(\"\\nNext steps:\")\n",
        "print(\"1. Run the procedures in file 09_create_model_functions.sql\")\n",
        "print(\"2. Deploy the Intelligence Agent in file 10_create_intelligence_agent.sql\")\n",
        "print(\"3. Test the agent in Snowsight AI & ML > Agents\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
