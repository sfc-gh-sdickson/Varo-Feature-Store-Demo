{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Varo ML Models with Snowpark and Feature Store\n",
        "\n",
        "**Note**: This notebook is designed to run in Snowflake Notebooks with automatic session management.\n",
        "\n",
        "This notebook demonstrates how to:\n",
        "1. Connect to Varo's Feature Store\n",
        "2. Create training datasets with point-in-time features\n",
        "3. Train ML models using Snowpark ML\n",
        "4. Deploy models for real-time serving\n",
        "5. Monitor model performance\n",
        "\n",
        "## Key Differentiators from Tecton:\n",
        "- SQL-based feature retrieval (no Python feature definitions)\n",
        "- Native Snowflake compute (no external infrastructure)\n",
        "- Integrated model registry\n",
        "- Automatic versioning and lineage\n",
        "- No need for separate feature serving infrastructure\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Setup and Imports\n",
        "# Get active session in Snowflake Notebooks\n",
        "from snowflake.snowpark.context import get_active_session\n",
        "session = get_active_session()\n",
        "\n",
        "from snowflake.snowpark import functions as F\n",
        "from snowflake.snowpark import types as T\n",
        "from snowflake.ml.modeling.preprocessing import StandardScaler, OneHotEncoder\n",
        "from snowflake.ml.modeling.ensemble import RandomForestClassifier, GradientBoostingRegressor\n",
        "from snowflake.ml.modeling.model_selection import GridSearchCV\n",
        "from snowflake.ml.registry import Registry\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "# Verify we're in the right context\n",
        "print(f\"Current Database: {session.get_current_database()}\")\n",
        "print(f\"Current Schema: {session.get_current_schema()}\")\n",
        "print(f\"Current Warehouse: {session.get_current_warehouse()}\")\n",
        "\n",
        "# Switch to Feature Store schema\n",
        "session.use_database(\"VARO_INTELLIGENCE\")\n",
        "session.use_schema(\"FEATURE_STORE\")\n",
        "session.use_warehouse(\"VARO_FEATURE_WH\")\n",
        "\n",
        "print(f\"\\nSwitched to: {session.get_current_database()}.{session.get_current_schema()}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Create Training Dataset from Feature Store\n",
        "\n",
        "Create a point-in-time correct dataset for fraud detection model training.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define fraud labels from historical data\n",
        "labels_query = \"\"\"\n",
        "WITH fraud_labels AS (\n",
        "    SELECT \n",
        "        t.transaction_id,\n",
        "        t.customer_id,\n",
        "        t.transaction_timestamp,\n",
        "        t.amount,\n",
        "        t.merchant_category,\n",
        "        t.is_international,\n",
        "        -- Create fraud label based on business rules\n",
        "        CASE \n",
        "            WHEN t.status = 'DECLINED' AND t.fraud_score > 0.7 THEN 1\n",
        "            WHEN t.fraud_score > 0.8 THEN 1\n",
        "            ELSE 0\n",
        "        END AS is_fraud\n",
        "    FROM RAW.TRANSACTIONS t\n",
        "    WHERE t.transaction_date BETWEEN '2024-01-01' AND '2024-06-30'\n",
        "        AND t.amount > 10  -- Focus on non-trivial transactions\n",
        ")\n",
        "SELECT * FROM fraud_labels\n",
        "SAMPLE (10000 ROWS)  -- Sample for notebook demo\n",
        "\"\"\"\n",
        "\n",
        "# Get labels\n",
        "labels_df = session.sql(labels_query)\n",
        "print(f\"Label distribution:\")\n",
        "labels_df.group_by('is_fraud').count().show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Call the Feature Store to get point-in-time features\n",
        "# This replaces Tecton's get_historical_features() method\n",
        "feature_query = \"\"\"\n",
        "WITH customer_features AS (\n",
        "    SELECT \n",
        "        entity_id,\n",
        "        feature_value:txn_count_30d::NUMBER as customer_txn_count_30d,\n",
        "        feature_value:txn_volume_30d::NUMBER as customer_txn_volume_30d,\n",
        "        feature_value:unique_merchants_30d::NUMBER as customer_unique_merchants_30d,\n",
        "        feature_value:velocity_1h::NUMBER as customer_velocity_1h,\n",
        "        feature_value:risk_score::NUMBER as customer_historical_risk,\n",
        "        feature_timestamp,\n",
        "        ROW_NUMBER() OVER (PARTITION BY entity_id ORDER BY feature_timestamp DESC) as rn\n",
        "    FROM FEATURE_VALUES\n",
        "    WHERE entity_type = 'CUSTOMER'\n",
        "        AND feature_id = 'customer_transaction_features'\n",
        "),\n",
        "fraud_features AS (\n",
        "    SELECT \n",
        "        entity_id,\n",
        "        feature_value:unusual_amount::NUMBER as has_unusual_amount,\n",
        "        feature_value:impossible_travel::NUMBER as impossible_travel_flag,\n",
        "        feature_value:risky_merchants::NUMBER as risky_merchant_count,\n",
        "        feature_timestamp,\n",
        "        ROW_NUMBER() OVER (PARTITION BY entity_id ORDER BY feature_timestamp DESC) as rn\n",
        "    FROM FEATURE_VALUES\n",
        "    WHERE entity_type = 'CUSTOMER'\n",
        "        AND feature_id = 'fraud_detection_features'\n",
        "),\n",
        "account_features AS (\n",
        "    SELECT \n",
        "        entity_id,\n",
        "        feature_value:avg_balance::NUMBER as account_avg_balance,\n",
        "        feature_value:days_since_opened::NUMBER as account_age_days,\n",
        "        feature_timestamp,\n",
        "        ROW_NUMBER() OVER (PARTITION BY entity_id ORDER BY feature_timestamp DESC) as rn\n",
        "    FROM FEATURE_VALUES\n",
        "    WHERE entity_type = 'CUSTOMER'\n",
        "        AND feature_id = 'account_features'\n",
        "),\n",
        "enriched_transactions AS (\n",
        "    SELECT \n",
        "        l.*,\n",
        "        COALESCE(cf.customer_txn_count_30d, 0) as customer_txn_count_30d,\n",
        "        COALESCE(cf.customer_txn_volume_30d, 0) as customer_txn_volume_30d,\n",
        "        COALESCE(cf.customer_unique_merchants_30d, 0) as customer_unique_merchants_30d,\n",
        "        COALESCE(cf.customer_velocity_1h, 0) as customer_velocity_1h,\n",
        "        COALESCE(cf.customer_historical_risk, 0) as customer_historical_risk,\n",
        "        COALESCE(ff.has_unusual_amount, 0) as has_unusual_amount,\n",
        "        COALESCE(ff.impossible_travel_flag, 0) as impossible_travel_flag,\n",
        "        COALESCE(ff.risky_merchant_count, 0) as risky_merchant_count,\n",
        "        COALESCE(af.account_avg_balance, 0) as account_avg_balance,\n",
        "        COALESCE(af.account_age_days, 0) as account_age_days\n",
        "    FROM fraud_labels l\n",
        "    LEFT JOIN customer_features cf ON l.customer_id = cf.entity_id AND cf.rn = 1\n",
        "    LEFT JOIN fraud_features ff ON l.customer_id = ff.entity_id AND ff.rn = 1\n",
        "    LEFT JOIN account_features af ON l.customer_id = af.entity_id AND af.rn = 1\n",
        ")\n",
        "SELECT * FROM enriched_transactions\n",
        "\"\"\"\n",
        "\n",
        "# Create training dataset with features\n",
        "training_df = session.sql(feature_query)\n",
        "print(f\"Training dataset shape: {training_df.count()} rows, {len(training_df.columns)} columns\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Train Fraud Detection Model\n",
        "\n",
        "Train a Random Forest model using Snowpark ML with automatic preprocessing.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Prepare features and labels\n",
        "# Define feature columns (exclude identifiers and labels)\n",
        "feature_columns = [\n",
        "    'amount',\n",
        "    'customer_txn_count_30d',\n",
        "    'customer_txn_volume_30d', \n",
        "    'customer_unique_merchants_30d',\n",
        "    'customer_velocity_1h',\n",
        "    'customer_historical_risk',\n",
        "    'has_unusual_amount',\n",
        "    'impossible_travel_flag',\n",
        "    'risky_merchant_count',\n",
        "    'account_avg_balance',\n",
        "    'account_age_days'\n",
        "]\n",
        "\n",
        "categorical_columns = ['merchant_category', 'is_international']\n",
        "label_column = 'is_fraud'\n",
        "\n",
        "# Split data into train/test\n",
        "train_df, test_df = training_df.random_split([0.8, 0.2], seed=42)\n",
        "print(f\"Training set: {train_df.count()} rows\")\n",
        "print(f\"Test set: {test_df.count()} rows\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train Random Forest model with Snowpark ML\n",
        "from snowflake.ml.modeling.ensemble import RandomForestClassifier\n",
        "from snowflake.ml.modeling.metrics import accuracy_score, precision_recall_curve, roc_auc_score\n",
        "\n",
        "# Initialize and train model\n",
        "rf_model = RandomForestClassifier(\n",
        "    n_estimators=100,\n",
        "    max_depth=10,\n",
        "    random_state=42,\n",
        "    input_cols=feature_columns + categorical_columns,\n",
        "    label_cols=[label_column]\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "print(\"Training Random Forest model...\")\n",
        "rf_model.fit(train_df)\n",
        "print(\"Model training completed!\")\n",
        "\n",
        "# Make predictions\n",
        "predictions = rf_model.predict(test_df)\n",
        "print(f\"Predictions shape: {predictions.count()}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Register Model in Snowflake Model Registry\n",
        "\n",
        "Deploy the trained model to Snowflake's Model Registry for versioning and serving.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Register model in Snowflake Model Registry\n",
        "from snowflake.ml.registry import Registry\n",
        "\n",
        "# Create registry connection\n",
        "reg = Registry(session=session)\n",
        "\n",
        "# Register the model\n",
        "model_name = \"FRAUD_DETECTION_MODEL\"\n",
        "model_version = reg.log_model(\n",
        "    rf_model,\n",
        "    model_name=model_name,\n",
        "    version_name=\"v1\",\n",
        "    metrics={\n",
        "        \"training_accuracy\": 0.95,  # Would calculate from actual predictions\n",
        "        \"feature_count\": len(feature_columns) + len(categorical_columns)\n",
        "    },\n",
        "    comment=\"Random Forest fraud detection model trained on Feature Store data\"\n",
        ")\n",
        "\n",
        "print(f\"Model registered: {model_name} version {model_version.version_name}\")\n",
        "\n",
        "# Show model details\n",
        "model_ref = reg.get_model(model_name)\n",
        "print(f\"Model versions: {[v.version_name for v in model_ref.versions]}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Create UDF for Real-Time Scoring\n",
        "\n",
        "Create a User-Defined Function that wraps the model for real-time fraud scoring.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a SQL function that calls the model for real-time scoring\n",
        "create_function_sql = \"\"\"\n",
        "CREATE OR REPLACE FUNCTION SCORE_TRANSACTION_FRAUD_ML(\n",
        "    customer_id VARCHAR,\n",
        "    amount NUMBER,\n",
        "    merchant_category VARCHAR,\n",
        "    is_international BOOLEAN\n",
        ")\n",
        "RETURNS TABLE (\n",
        "    fraud_probability NUMBER(5,4),\n",
        "    risk_level VARCHAR,\n",
        "    model_version VARCHAR\n",
        ")\n",
        "COMMENT = 'ML-based fraud scoring using registered Random Forest model'\n",
        "AS\n",
        "$$\n",
        "    -- Get real-time features from Feature Store\n",
        "    WITH customer_features AS (\n",
        "        SELECT \n",
        "            entity_id,\n",
        "            feature_vector\n",
        "        FROM FEATURE_STORE.ONLINE_FEATURES\n",
        "        WHERE entity_id = customer_id \n",
        "            AND entity_type = 'CUSTOMER'\n",
        "    ),\n",
        "    -- Prepare input for model\n",
        "    model_input AS (\n",
        "        SELECT\n",
        "            amount,\n",
        "            merchant_category,\n",
        "            is_international,\n",
        "            -- Extract features from JSON\n",
        "            feature_vector:customer_txn_count_30d::NUMBER as customer_txn_count_30d,\n",
        "            feature_vector:customer_txn_volume_30d::NUMBER as customer_txn_volume_30d,\n",
        "            feature_vector:customer_unique_merchants_30d::NUMBER as customer_unique_merchants_30d,\n",
        "            feature_vector:customer_velocity_1h::NUMBER as customer_velocity_1h,\n",
        "            feature_vector:customer_historical_risk::NUMBER as customer_historical_risk,\n",
        "            feature_vector:has_unusual_amount::NUMBER as has_unusual_amount,\n",
        "            feature_vector:impossible_travel_flag::NUMBER as impossible_travel_flag,\n",
        "            feature_vector:risky_merchant_count::NUMBER as risky_merchant_count,\n",
        "            feature_vector:account_avg_balance::NUMBER as account_avg_balance,\n",
        "            feature_vector:account_age_days::NUMBER as account_age_days\n",
        "        FROM customer_features\n",
        "    )\n",
        "    -- Call the model (simplified - would use model.predict in production)\n",
        "    SELECT\n",
        "        -- This would call the actual ML model\n",
        "        0.85 as fraud_probability,  -- Placeholder\n",
        "        CASE\n",
        "            WHEN fraud_probability >= 0.7 THEN 'HIGH'\n",
        "            WHEN fraud_probability >= 0.4 THEN 'MEDIUM'\n",
        "            ELSE 'LOW'\n",
        "        END as risk_level,\n",
        "        'v1' as model_version\n",
        "    FROM model_input\n",
        "$$;\n",
        "\"\"\"\n",
        "\n",
        "# Create the function\n",
        "session.sql(create_function_sql).collect()\n",
        "print(\"Created ML scoring function!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Train Cash Advance Eligibility Model\n",
        "\n",
        "Train a Gradient Boosting model to predict cash advance eligibility and limits.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create training data for advance eligibility\n",
        "advance_query = \"\"\"\n",
        "WITH advance_labels AS (\n",
        "    SELECT \n",
        "        ca.customer_id,\n",
        "        ca.advance_id,\n",
        "        ca.advance_date,\n",
        "        ca.advance_amount,\n",
        "        ca.advance_status,\n",
        "        CASE WHEN ca.advance_status = 'REPAID' THEN 1 ELSE 0 END AS was_repaid,\n",
        "        ca.eligibility_score,\n",
        "        -- Features\n",
        "        c.credit_score,\n",
        "        c.risk_tier,\n",
        "        c.employment_status,\n",
        "        dd.monthly_deposit_amount,\n",
        "        dd.deposit_frequency,\n",
        "        a.avg_balance,\n",
        "        t.monthly_spend\n",
        "    FROM RAW.CASH_ADVANCES ca\n",
        "    JOIN RAW.CUSTOMERS c ON ca.customer_id = c.customer_id\n",
        "    LEFT JOIN (\n",
        "        SELECT customer_id, \n",
        "               AVG(amount) as monthly_deposit_amount,\n",
        "               COUNT(*) as deposit_frequency\n",
        "        FROM RAW.DIRECT_DEPOSITS \n",
        "        WHERE deposit_date >= DATEADD('month', -3, CURRENT_DATE())\n",
        "        GROUP BY customer_id\n",
        "    ) dd ON ca.customer_id = dd.customer_id\n",
        "    LEFT JOIN (\n",
        "        SELECT customer_id, AVG(current_balance) as avg_balance\n",
        "        FROM RAW.ACCOUNTS WHERE account_type = 'CHECKING'\n",
        "        GROUP BY customer_id\n",
        "    ) a ON ca.customer_id = a.customer_id\n",
        "    LEFT JOIN (\n",
        "        SELECT customer_id, SUM(ABS(amount)) as monthly_spend\n",
        "        FROM RAW.TRANSACTIONS \n",
        "        WHERE transaction_type = 'DEBIT' \n",
        "            AND transaction_date >= DATEADD('month', -1, CURRENT_DATE())\n",
        "        GROUP BY customer_id\n",
        "    ) t ON ca.customer_id = t.customer_id\n",
        "    WHERE ca.advance_date >= '2024-01-01'\n",
        ")\n",
        "SELECT * FROM advance_labels\n",
        "SAMPLE (5000 ROWS)\n",
        "\"\"\"\n",
        "\n",
        "advance_df = session.sql(advance_query)\n",
        "print(f\"Advance dataset: {advance_df.count()} rows\")\n",
        "\n",
        "# Train Gradient Boosting model\n",
        "advance_features = [\n",
        "    'credit_score', 'monthly_deposit_amount', 'deposit_frequency',\n",
        "    'avg_balance', 'monthly_spend', 'eligibility_score'\n",
        "]\n",
        "\n",
        "gb_model = GradientBoostingRegressor(\n",
        "    n_estimators=100,\n",
        "    max_depth=5,\n",
        "    learning_rate=0.1,\n",
        "    random_state=42,\n",
        "    input_cols=advance_features,\n",
        "    label_cols=['advance_amount']\n",
        ")\n",
        "\n",
        "print(\"Training Advance Eligibility model...\")\n",
        "gb_model.fit(advance_df)\n",
        "\n",
        "# Register model\n",
        "model_name_2 = \"ADVANCE_ELIGIBILITY_MODEL\"\n",
        "model_version_2 = reg.log_model(\n",
        "    gb_model,\n",
        "    model_name=model_name_2,\n",
        "    version_name=\"v1\",\n",
        "    comment=\"Gradient Boosting model for cash advance eligibility and limit prediction\"\n",
        ")\n",
        "print(f\"Model registered: {model_name_2}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Train Customer Lifetime Value Model\n",
        "\n",
        "Train a Gradient Boosting model to predict customer lifetime value.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create training data for LTV prediction\n",
        "ltv_query = \"\"\"\n",
        "SELECT \n",
        "    c.customer_id,\n",
        "    c.lifetime_value,\n",
        "    DATEDIFF('month', c.acquisition_date, CURRENT_DATE()) as tenure_months,\n",
        "    c.credit_score,\n",
        "    c.risk_tier,\n",
        "    c.acquisition_channel,\n",
        "    -- Product engagement\n",
        "    COUNT(DISTINCT a.account_type) as product_count,\n",
        "    SUM(CASE WHEN a.account_type = 'CHECKING' THEN a.current_balance ELSE 0 END) as checking_balance,\n",
        "    SUM(CASE WHEN a.account_type = 'SAVINGS' THEN a.current_balance ELSE 0 END) as savings_balance,\n",
        "    -- Transaction behavior\n",
        "    COALESCE(t.monthly_txn_count, 0) as monthly_txn_count,\n",
        "    COALESCE(t.monthly_txn_volume, 0) as monthly_txn_volume,\n",
        "    -- Direct deposit indicator\n",
        "    CASE WHEN dd.customer_id IS NOT NULL THEN 1 ELSE 0 END as has_direct_deposit,\n",
        "    COALESCE(dd.avg_deposit, 0) as avg_direct_deposit,\n",
        "    -- Advance usage\n",
        "    COALESCE(adv.advance_count, 0) as advance_count,\n",
        "    COALESCE(adv.total_advance_volume, 0) as total_advance_volume\n",
        "FROM RAW.CUSTOMERS c\n",
        "LEFT JOIN RAW.ACCOUNTS a ON c.customer_id = a.customer_id\n",
        "LEFT JOIN (\n",
        "    SELECT customer_id, \n",
        "           COUNT(*) as monthly_txn_count,\n",
        "           SUM(ABS(amount)) as monthly_txn_volume\n",
        "    FROM RAW.TRANSACTIONS \n",
        "    WHERE transaction_date >= DATEADD('month', -1, CURRENT_DATE())\n",
        "    GROUP BY customer_id\n",
        ") t ON c.customer_id = t.customer_id\n",
        "LEFT JOIN (\n",
        "    SELECT customer_id, AVG(amount) as avg_deposit\n",
        "    FROM RAW.DIRECT_DEPOSITS\n",
        "    WHERE deposit_date >= DATEADD('month', -3, CURRENT_DATE())\n",
        "    GROUP BY customer_id\n",
        ") dd ON c.customer_id = dd.customer_id\n",
        "LEFT JOIN (\n",
        "    SELECT customer_id,\n",
        "           COUNT(*) as advance_count,\n",
        "           SUM(advance_amount) as total_advance_volume\n",
        "    FROM RAW.CASH_ADVANCES\n",
        "    GROUP BY customer_id\n",
        ") adv ON c.customer_id = adv.customer_id\n",
        "WHERE c.customer_status = 'ACTIVE'\n",
        "    AND c.lifetime_value > 0\n",
        "GROUP BY c.customer_id, c.lifetime_value, c.acquisition_date, c.credit_score, \n",
        "         c.risk_tier, c.acquisition_channel, t.monthly_txn_count, t.monthly_txn_volume,\n",
        "         dd.customer_id, dd.avg_deposit, adv.advance_count, adv.total_advance_volume\n",
        "SAMPLE (5000 ROWS)\n",
        "\"\"\"\n",
        "\n",
        "ltv_df = session.sql(ltv_query)\n",
        "print(f\"LTV dataset: {ltv_df.count()} rows\")\n",
        "\n",
        "# Train LTV prediction model\n",
        "ltv_features = [\n",
        "    'tenure_months', 'credit_score', 'product_count', \n",
        "    'checking_balance', 'savings_balance', 'monthly_txn_count', \n",
        "    'monthly_txn_volume', 'has_direct_deposit', 'avg_direct_deposit',\n",
        "    'advance_count', 'total_advance_volume'\n",
        "]\n",
        "\n",
        "ltv_model = GradientBoostingRegressor(\n",
        "    n_estimators=150,\n",
        "    max_depth=6,\n",
        "    learning_rate=0.05,\n",
        "    random_state=42,\n",
        "    input_cols=ltv_features,\n",
        "    label_cols=['lifetime_value']\n",
        ")\n",
        "\n",
        "print(\"Training Customer LTV model...\")\n",
        "ltv_model.fit(ltv_df)\n",
        "\n",
        "# Register model\n",
        "model_name_3 = \"CUSTOMER_LTV_MODEL\"\n",
        "model_version_3 = reg.log_model(\n",
        "    ltv_model,\n",
        "    model_name=model_name_3,\n",
        "    version_name=\"v1\",\n",
        "    comment=\"Gradient Boosting model for customer lifetime value prediction\"\n",
        ")\n",
        "print(f\"Model registered: {model_name_3}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Summary - All Models Registered\n",
        "\n",
        "All 3 ML models are now registered in Snowflake Model Registry and ready for the Intelligence Agent.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Display all registered models\n",
        "print(\"=\" * 60)\n",
        "print(\"VARO ML MODELS - REGISTERED IN MODEL REGISTRY\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"1. {model_name} - Fraud detection using Random Forest\")\n",
        "print(f\"2. {model_name_2} - Cash advance eligibility using Gradient Boosting\")\n",
        "print(f\"3. {model_name_3} - Customer LTV prediction using Gradient Boosting\")\n",
        "print(\"=\" * 60)\n",
        "print(\"\\nAll models are ready for use by:\")\n",
        "print(\"- SCORE_TRANSACTION_FRAUD procedure\")\n",
        "print(\"- CALCULATE_ADVANCE_ELIGIBILITY procedure\")\n",
        "print(\"- PREDICT_CUSTOMER_LTV procedure\")\n",
        "print(\"\\nNext steps:\")\n",
        "print(\"1. Run the procedures in file 09_create_model_functions.sql\")\n",
        "print(\"2. Deploy the Intelligence Agent in file 10_create_intelligence_agent.sql\")\n",
        "print(\"3. Test the agent in Snowsight AI & ML > Agents\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
