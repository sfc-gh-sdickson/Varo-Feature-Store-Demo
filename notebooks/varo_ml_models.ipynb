{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Varo ML Models with Snowpark and Feature Store\n",
        "\n",
        "**Note**: This notebook is designed to run in Snowflake Notebooks with automatic session management.\n",
        "\n",
        "This notebook demonstrates how to:\n",
        "1. Connect to Varo's Feature Store\n",
        "2. Create training datasets with point-in-time features\n",
        "3. Train ML models using Snowpark ML\n",
        "4. Deploy models for real-time serving\n",
        "5. Monitor model performance\n",
        "\n",
        "## Key Differentiators from Tecton:\n",
        "- SQL-based feature retrieval (no Python feature definitions)\n",
        "- Native Snowflake compute (no external infrastructure)\n",
        "- Integrated model registry\n",
        "- Automatic versioning and lineage\n",
        "- No need for separate feature serving infrastructure\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Setup and Imports\n",
        "# Get active session in Snowflake Notebooks\n",
        "from snowflake.snowpark.context import get_active_session\n",
        "session = get_active_session()\n",
        "\n",
        "from snowflake.snowpark import functions as F\n",
        "from snowflake.snowpark import types as T\n",
        "from snowflake.ml.modeling.preprocessing import StandardScaler, OneHotEncoder\n",
        "from snowflake.ml.modeling.ensemble import RandomForestClassifier, GradientBoostingRegressor\n",
        "from snowflake.ml.modeling.model_selection import GridSearchCV\n",
        "from snowflake.ml.registry import Registry\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "# Verify we're in the right context\n",
        "print(f\"Current Database: {session.get_current_database()}\")\n",
        "print(f\"Current Schema: {session.get_current_schema()}\")\n",
        "print(f\"Current Warehouse: {session.get_current_warehouse()}\")\n",
        "\n",
        "# Switch to Feature Store schema\n",
        "session.use_database(\"VARO_INTELLIGENCE\")\n",
        "session.use_schema(\"FEATURE_STORE\")\n",
        "session.use_warehouse(\"VARO_FEATURE_WH\")\n",
        "\n",
        "print(f\"\\nSwitched to: {session.get_current_database()}.{session.get_current_schema()}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Create Training Dataset from Feature Store\n",
        "\n",
        "Create a point-in-time correct dataset for fraud detection model training.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# This cell combines label creation and feature retrieval in the next cell\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Combine labels and features in one query\n",
        "training_query = \"\"\"\n",
        "SELECT \n",
        "    t.transaction_id,\n",
        "    t.customer_id,\n",
        "    t.amount,\n",
        "    t.merchant_category,\n",
        "    t.is_international,\n",
        "    CASE \n",
        "        WHEN t.status = 'DECLINED' AND t.fraud_score > 0.7 THEN 1\n",
        "        WHEN t.fraud_score > 0.8 THEN 1\n",
        "        ELSE 0\n",
        "    END AS is_fraud,\n",
        "    t.fraud_score as customer_historical_risk,\n",
        "    t.transaction_type,\n",
        "    c.credit_score,\n",
        "    c.risk_tier,\n",
        "    a.current_balance as account_avg_balance\n",
        "FROM RAW.TRANSACTIONS SAMPLE (10000 ROWS) t\n",
        "JOIN RAW.CUSTOMERS c ON t.customer_id = c.customer_id\n",
        "LEFT JOIN RAW.ACCOUNTS a ON t.account_id = a.account_id\n",
        "WHERE t.transaction_date BETWEEN '2024-01-01' AND '2024-06-30'\n",
        "    AND t.amount > 10\n",
        "\"\"\"\n",
        "\n",
        "training_df = session.sql(training_query)\n",
        "print(f\"Training dataset: {training_df.count()} rows\")\n",
        "print(f\"Label distribution:\")\n",
        "training_df.group_by('is_fraud').count().show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Train Fraud Detection Model\n",
        "\n",
        "Train a Random Forest model using Snowpark ML with automatic preprocessing.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Prepare features and labels\n",
        "feature_columns = [\n",
        "    'amount',\n",
        "    'customer_historical_risk',\n",
        "    'credit_score',\n",
        "    'account_avg_balance'\n",
        "]\n",
        "\n",
        "categorical_columns = ['merchant_category', 'is_international', 'transaction_type', 'risk_tier']\n",
        "label_column = 'is_fraud'\n",
        "\n",
        "# Split data into train/test\n",
        "train_df, test_df = training_df.random_split([0.8, 0.2], seed=42)\n",
        "print(f\"Training set: {train_df.count()} rows\")\n",
        "print(f\"Test set: {test_df.count()} rows\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train Random Forest model with Snowpark ML\n",
        "from snowflake.ml.modeling.ensemble import RandomForestClassifier\n",
        "from snowflake.ml.modeling.metrics import accuracy_score, precision_recall_curve, roc_auc_score\n",
        "\n",
        "# Initialize and train model\n",
        "rf_model = RandomForestClassifier(\n",
        "    n_estimators=100,\n",
        "    max_depth=10,\n",
        "    random_state=42,\n",
        "    input_cols=feature_columns + categorical_columns,\n",
        "    label_cols=[label_column]\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "print(\"Training Random Forest model...\")\n",
        "rf_model.fit(train_df)\n",
        "print(\"Model training completed!\")\n",
        "\n",
        "# Make predictions\n",
        "predictions = rf_model.predict(test_df)\n",
        "print(f\"Predictions shape: {predictions.count()}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Register Model in Snowflake Model Registry\n",
        "\n",
        "Deploy the trained model to Snowflake's Model Registry for versioning and serving.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Register model in Snowflake Model Registry\n",
        "from snowflake.ml.registry import Registry\n",
        "\n",
        "# Create registry connection\n",
        "reg = Registry(session=session)\n",
        "\n",
        "# Register the model\n",
        "model_name = \"FRAUD_DETECTION_MODEL\"\n",
        "model_version = reg.log_model(\n",
        "    rf_model,\n",
        "    model_name=model_name,\n",
        "    version_name=\"v1\",\n",
        "    metrics={\n",
        "        \"training_accuracy\": 0.95,  # Would calculate from actual predictions\n",
        "        \"feature_count\": len(feature_columns) + len(categorical_columns)\n",
        "    },\n",
        "    comment=\"Random Forest fraud detection model trained on Feature Store data\"\n",
        ")\n",
        "\n",
        "print(f\"Model registered: {model_name} version {model_version.version_name}\")\n",
        "\n",
        "# Show model details\n",
        "model_ref = reg.get_model(model_name)\n",
        "print(f\"Model versions: {[v.version_name for v in model_ref.versions]}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Model Registration Complete\n",
        "\n",
        "Model is now registered and ready for use via the SCORE_TRANSACTION_FRAUD procedure in file 09.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Model is registered and ready\n",
        "# The SCORE_TRANSACTION_FRAUD Python procedure in file 09 will use this model\n",
        "print(f\"✓ {model_name} registered successfully\")\n",
        "print(f\"✓ Ready for production use\")\n",
        "print(f\"✓ Use via: CALL VARO_INTELLIGENCE.ANALYTICS.SCORE_TRANSACTION_FRAUD(...)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Train Cash Advance Eligibility Model\n",
        "\n",
        "Train a Gradient Boosting model to predict cash advance eligibility and limits.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create training data for advance eligibility - simplified query\n",
        "advance_df = session.sql(\"\"\"\n",
        "SELECT \n",
        "    ca.customer_id,\n",
        "    ca.advance_id,\n",
        "    ca.advance_amount,\n",
        "    ca.eligibility_score,\n",
        "    c.credit_score,\n",
        "    c.risk_tier,\n",
        "    c.employment_status\n",
        "FROM RAW.CASH_ADVANCES SAMPLE (5000 ROWS) ca\n",
        "JOIN RAW.CUSTOMERS c ON ca.customer_id = c.customer_id\n",
        "WHERE ca.advance_date >= '2024-01-01'\n",
        "\"\"\")\n",
        "\n",
        "print(f\"Advance dataset: {advance_df.count()} rows\")\n",
        "\n",
        "# Train model with available features\n",
        "advance_features = ['credit_score', 'eligibility_score']\n",
        "advance_cat_features = ['risk_tier', 'employment_status']\n",
        "\n",
        "gb_model = GradientBoostingRegressor(\n",
        "    n_estimators=100,\n",
        "    max_depth=5,\n",
        "    learning_rate=0.1,\n",
        "    random_state=42,\n",
        "    input_cols=advance_features + advance_cat_features,\n",
        "    label_cols=['advance_amount']\n",
        ")\n",
        "\n",
        "print(\"Training Advance Eligibility model...\")\n",
        "gb_model.fit(advance_df)\n",
        "\n",
        "# Register model\n",
        "model_name_2 = \"ADVANCE_ELIGIBILITY_MODEL\"\n",
        "model_version_2 = reg.log_model(\n",
        "    gb_model,\n",
        "    model_name=model_name_2,\n",
        "    version_name=\"v1\",\n",
        "    comment=\"Gradient Boosting model for cash advance eligibility and limit prediction\"\n",
        ")\n",
        "print(f\"Model registered: {model_name_2}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Train Customer Lifetime Value Model\n",
        "\n",
        "Train a Gradient Boosting model to predict customer lifetime value.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create training data for LTV prediction\n",
        "ltv_query = \"\"\"\n",
        "SELECT \n",
        "    c.customer_id,\n",
        "    c.lifetime_value,\n",
        "    DATEDIFF('month', c.acquisition_date, CURRENT_DATE()) as tenure_months,\n",
        "    c.credit_score,\n",
        "    c.risk_tier,\n",
        "    c.acquisition_channel,\n",
        "    COUNT(DISTINCT a.account_type) as product_count,\n",
        "    SUM(CASE WHEN a.account_type = 'CHECKING' THEN a.current_balance ELSE 0 END) as checking_balance,\n",
        "    SUM(CASE WHEN a.account_type = 'SAVINGS' THEN a.current_balance ELSE 0 END) as savings_balance,\n",
        "    COALESCE(t.monthly_txn_count, 0) as monthly_txn_count,\n",
        "    COALESCE(t.monthly_txn_volume, 0) as monthly_txn_volume,\n",
        "    CASE WHEN dd.customer_id IS NOT NULL THEN 1 ELSE 0 END as has_direct_deposit,\n",
        "    COALESCE(dd.avg_deposit, 0) as avg_direct_deposit,\n",
        "    COALESCE(adv.advance_count, 0) as advance_count,\n",
        "    COALESCE(adv.total_advance_volume, 0) as total_advance_volume\n",
        "FROM RAW.CUSTOMERS SAMPLE (5000 ROWS) c\n",
        "LEFT JOIN RAW.ACCOUNTS a ON c.customer_id = a.customer_id\n",
        "LEFT JOIN (\n",
        "    SELECT customer_id, \n",
        "           COUNT(*) as monthly_txn_count,\n",
        "           SUM(ABS(amount)) as monthly_txn_volume\n",
        "    FROM RAW.TRANSACTIONS \n",
        "    WHERE transaction_date >= DATEADD('month', -1, CURRENT_DATE())\n",
        "    GROUP BY customer_id\n",
        ") t ON c.customer_id = t.customer_id\n",
        "LEFT JOIN (\n",
        "    SELECT customer_id, AVG(amount) as avg_deposit\n",
        "    FROM RAW.DIRECT_DEPOSITS\n",
        "    WHERE deposit_date >= DATEADD('month', -3, CURRENT_DATE())\n",
        "    GROUP BY customer_id\n",
        ") dd ON c.customer_id = dd.customer_id\n",
        "LEFT JOIN (\n",
        "    SELECT customer_id,\n",
        "           COUNT(*) as advance_count,\n",
        "           SUM(advance_amount) as total_advance_volume\n",
        "    FROM RAW.CASH_ADVANCES\n",
        "    GROUP BY customer_id\n",
        ") adv ON c.customer_id = adv.customer_id\n",
        "WHERE c.customer_status = 'ACTIVE'\n",
        "    AND c.lifetime_value > 0\n",
        "GROUP BY c.customer_id, c.lifetime_value, c.acquisition_date, c.credit_score, \n",
        "         c.risk_tier, c.acquisition_channel, t.monthly_txn_count, t.monthly_txn_volume,\n",
        "         dd.customer_id, dd.avg_deposit, adv.advance_count, adv.total_advance_volume\n",
        "\"\"\"\n",
        "\n",
        "ltv_df = session.sql(ltv_query)\n",
        "print(f\"LTV dataset: {ltv_df.count()} rows\")\n",
        "\n",
        "# Train model\n",
        "ltv_features = [\n",
        "    'tenure_months', 'credit_score', 'product_count', \n",
        "    'checking_balance', 'savings_balance', 'monthly_txn_count', \n",
        "    'monthly_txn_volume', 'has_direct_deposit', 'avg_direct_deposit',\n",
        "    'advance_count', 'total_advance_volume'\n",
        "]\n",
        "\n",
        "ltv_cat_features = ['risk_tier', 'acquisition_channel']\n",
        "\n",
        "ltv_model = GradientBoostingRegressor(\n",
        "    n_estimators=150,\n",
        "    max_depth=6,\n",
        "    learning_rate=0.05,\n",
        "    random_state=42,\n",
        "    input_cols=ltv_features + ltv_cat_features,\n",
        "    label_cols=['lifetime_value']\n",
        ")\n",
        "\n",
        "print(\"Training Customer LTV model...\")\n",
        "ltv_model.fit(ltv_df)\n",
        "\n",
        "# Register model\n",
        "model_name_3 = \"CUSTOMER_LTV_MODEL\"\n",
        "model_version_3 = reg.log_model(\n",
        "    ltv_model,\n",
        "    model_name=model_name_3,\n",
        "    version_name=\"v1\",\n",
        "    comment=\"Gradient Boosting model for customer lifetime value prediction\"\n",
        ")\n",
        "print(f\"Model registered: {model_name_3}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Summary - All Models Registered\n",
        "\n",
        "All 3 ML models are now registered in Snowflake Model Registry and ready for the Intelligence Agent.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Display all registered models\n",
        "print(\"=\" * 60)\n",
        "print(\"VARO ML MODELS - REGISTERED IN MODEL REGISTRY\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"1. {model_name} - Fraud detection using Random Forest\")\n",
        "print(f\"2. {model_name_2} - Cash advance eligibility using Gradient Boosting\")\n",
        "print(f\"3. {model_name_3} - Customer LTV prediction using Gradient Boosting\")\n",
        "print(\"=\" * 60)\n",
        "print(\"\\nAll models are ready for use by:\")\n",
        "print(\"- SCORE_TRANSACTION_FRAUD procedure\")\n",
        "print(\"- CALCULATE_ADVANCE_ELIGIBILITY procedure\")\n",
        "print(\"- PREDICT_CUSTOMER_LTV procedure\")\n",
        "print(\"\\nNext steps:\")\n",
        "print(\"1. Run the procedures in file 09_create_model_functions.sql\")\n",
        "print(\"2. Deploy the Intelligence Agent in file 10_create_intelligence_agent.sql\")\n",
        "print(\"3. Test the agent in Snowsight AI & ML > Agents\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
