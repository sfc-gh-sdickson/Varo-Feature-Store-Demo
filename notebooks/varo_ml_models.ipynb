{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Varo ML Models with Snowpark and Feature Store\n",
        "\n",
        "**Note**: This notebook is designed to run in Snowflake Notebooks with automatic session management.\n",
        "\n",
        "This notebook demonstrates how to:\n",
        "1. Connect to Varo's Feature Store\n",
        "2. Create training datasets with point-in-time features\n",
        "3. Train ML models using Snowpark ML\n",
        "4. Deploy models for real-time serving\n",
        "5. Monitor model performance\n",
        "\n",
        "## Key Differentiators from Tecton:\n",
        "- SQL-based feature retrieval (no Python feature definitions)\n",
        "- Native Snowflake compute (no external infrastructure)\n",
        "- Integrated model registry\n",
        "- Automatic versioning and lineage\n",
        "- No need for separate feature serving infrastructure\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Setup and Imports\n",
        "# In Snowflake Notebooks, the session is automatically available as 'session'\n",
        "from snowflake.snowpark import functions as F\n",
        "from snowflake.snowpark import types as T\n",
        "from snowflake.ml.modeling.preprocessing import StandardScaler, OneHotEncoder\n",
        "from snowflake.ml.modeling.ensemble import RandomForestClassifier, GradientBoostingRegressor\n",
        "from snowflake.ml.modeling.model_selection import GridSearchCV\n",
        "from snowflake.ml.registry import Registry\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "# Verify we're in the right context\n",
        "print(f\"Current Database: {session.get_current_database()}\")\n",
        "print(f\"Current Schema: {session.get_current_schema()}\")\n",
        "print(f\"Current Warehouse: {session.get_current_warehouse()}\")\n",
        "\n",
        "# Switch to Feature Store schema\n",
        "session.use_database(\"VARO_INTELLIGENCE\")\n",
        "session.use_schema(\"FEATURE_STORE\")\n",
        "session.use_warehouse(\"VARO_FEATURE_WH\")\n",
        "\n",
        "print(f\"\\nSwitched to: {session.get_current_database()}.{session.get_current_schema()}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Create Training Dataset from Feature Store\n",
        "\n",
        "Create a point-in-time correct dataset for fraud detection model training.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define fraud labels from historical data\n",
        "labels_query = \"\"\"\n",
        "WITH fraud_labels AS (\n",
        "    SELECT \n",
        "        t.transaction_id,\n",
        "        t.customer_id,\n",
        "        t.transaction_timestamp,\n",
        "        t.amount,\n",
        "        t.merchant_category,\n",
        "        t.is_international,\n",
        "        -- Create fraud label based on business rules or known fraud cases\n",
        "        CASE \n",
        "            WHEN t.status = 'DECLINED' AND t.fraud_score > 0.7 THEN 1\n",
        "            WHEN ce.event_type = 'FRAUD_CONFIRMED' THEN 1\n",
        "            ELSE 0\n",
        "        END AS is_fraud\n",
        "    FROM RAW.TRANSACTIONS t\n",
        "    LEFT JOIN RAW.COMPLIANCE_EVENTS ce \n",
        "        ON t.transaction_id = ce.transaction_id \n",
        "        AND ce.event_type = 'FRAUD_CONFIRMED'\n",
        "    WHERE t.transaction_date BETWEEN '2024-01-01' AND '2024-06-30'\n",
        "        AND t.amount > 10  -- Focus on non-trivial transactions\n",
        ")\n",
        "SELECT * FROM fraud_labels\n",
        "SAMPLE (10000 ROWS)  -- Sample for notebook demo\n",
        "\"\"\"\n",
        "\n",
        "# Get labels\n",
        "labels_df = session.sql(labels_query)\n",
        "print(f\"Label distribution: {labels_df.group_by('is_fraud').count().show()}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Call the Feature Store to get point-in-time features\n",
        "# This replaces Tecton's get_historical_features() method\n",
        "feature_query = \"\"\"\n",
        "WITH enriched_transactions AS (\n",
        "    SELECT \n",
        "        l.*,\n",
        "        -- Get customer features as of transaction time\n",
        "        cf.feature_value:txn_count_30d::NUMBER as customer_txn_count_30d,\n",
        "        cf.feature_value:txn_volume_30d::NUMBER as customer_txn_volume_30d,\n",
        "        cf.feature_value:unique_merchants_30d::NUMBER as customer_unique_merchants_30d,\n",
        "        cf.feature_value:velocity_1h::NUMBER as customer_velocity_1h,\n",
        "        cf.feature_value:risk_score::NUMBER as customer_historical_risk,\n",
        "        \n",
        "        -- Get fraud features as of transaction time\n",
        "        ff.feature_value:unusual_amount::NUMBER as has_unusual_amount,\n",
        "        ff.feature_value:impossible_travel::NUMBER as impossible_travel_flag,\n",
        "        ff.feature_value:risky_merchants::NUMBER as risky_merchant_count,\n",
        "        \n",
        "        -- Get account features\n",
        "        af.feature_value:avg_balance::NUMBER as account_avg_balance,\n",
        "        af.feature_value:days_since_opened::NUMBER as account_age_days\n",
        "        \n",
        "    FROM fraud_labels l\n",
        "    LEFT JOIN FEATURE_VALUES cf\n",
        "        ON l.customer_id = cf.entity_id \n",
        "        AND cf.entity_type = 'CUSTOMER'\n",
        "        AND cf.feature_id = 'customer_transaction_features'\n",
        "        AND cf.feature_timestamp <= l.transaction_timestamp\n",
        "        QUALIFY ROW_NUMBER() OVER (PARTITION BY l.transaction_id ORDER BY cf.feature_timestamp DESC) = 1\n",
        "        \n",
        "    LEFT JOIN FEATURE_VALUES ff\n",
        "        ON l.customer_id = ff.entity_id\n",
        "        AND ff.entity_type = 'CUSTOMER' \n",
        "        AND ff.feature_id = 'fraud_detection_features'\n",
        "        AND ff.feature_timestamp <= l.transaction_timestamp\n",
        "        QUALIFY ROW_NUMBER() OVER (PARTITION BY l.transaction_id ORDER BY ff.feature_timestamp DESC) = 1\n",
        "        \n",
        "    LEFT JOIN FEATURE_VALUES af\n",
        "        ON l.customer_id = af.entity_id\n",
        "        AND af.entity_type = 'CUSTOMER'\n",
        "        AND af.feature_id = 'account_features'\n",
        "        AND af.feature_timestamp <= l.transaction_timestamp\n",
        "        QUALIFY ROW_NUMBER() OVER (PARTITION BY l.transaction_id ORDER BY af.feature_timestamp DESC) = 1\n",
        ")\n",
        "SELECT * FROM enriched_transactions\n",
        "\"\"\"\n",
        "\n",
        "# Create training dataset with features\n",
        "training_df = session.sql(feature_query)\n",
        "print(f\"Training dataset shape: {training_df.count()} rows, {len(training_df.columns)} columns\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Train Fraud Detection Model\n",
        "\n",
        "Train a Random Forest model using Snowpark ML with automatic preprocessing.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Prepare features and labels\n",
        "# Define feature columns (exclude identifiers and labels)\n",
        "feature_columns = [\n",
        "    'amount',\n",
        "    'customer_txn_count_30d',\n",
        "    'customer_txn_volume_30d', \n",
        "    'customer_unique_merchants_30d',\n",
        "    'customer_velocity_1h',\n",
        "    'customer_historical_risk',\n",
        "    'has_unusual_amount',\n",
        "    'impossible_travel_flag',\n",
        "    'risky_merchant_count',\n",
        "    'account_avg_balance',\n",
        "    'account_age_days'\n",
        "]\n",
        "\n",
        "categorical_columns = ['merchant_category', 'is_international']\n",
        "label_column = 'is_fraud'\n",
        "\n",
        "# Split data into train/test\n",
        "train_df, test_df = training_df.random_split([0.8, 0.2], seed=42)\n",
        "print(f\"Training set: {train_df.count()} rows\")\n",
        "print(f\"Test set: {test_df.count()} rows\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train Random Forest model with Snowpark ML\n",
        "from snowflake.ml.modeling.ensemble import RandomForestClassifier\n",
        "from snowflake.ml.modeling.metrics import accuracy_score, precision_recall_curve, roc_auc_score\n",
        "\n",
        "# Initialize and train model\n",
        "rf_model = RandomForestClassifier(\n",
        "    n_estimators=100,\n",
        "    max_depth=10,\n",
        "    random_state=42,\n",
        "    input_cols=feature_columns + categorical_columns,\n",
        "    label_cols=[label_column]\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "print(\"Training Random Forest model...\")\n",
        "rf_model.fit(train_df)\n",
        "print(\"Model training completed!\")\n",
        "\n",
        "# Make predictions\n",
        "predictions = rf_model.predict(test_df)\n",
        "print(f\"Predictions shape: {predictions.count()}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Register Model in Snowflake Model Registry\n",
        "\n",
        "Deploy the trained model to Snowflake's Model Registry for versioning and serving.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Register model in Snowflake Model Registry\n",
        "from snowflake.ml.registry import Registry\n",
        "\n",
        "# Create registry connection\n",
        "reg = Registry(session=session)\n",
        "\n",
        "# Register the model\n",
        "model_name = \"FRAUD_DETECTION_MODEL\"\n",
        "model_version = reg.log_model(\n",
        "    rf_model,\n",
        "    model_name=model_name,\n",
        "    version_name=\"v1\",\n",
        "    metrics={\n",
        "        \"training_accuracy\": 0.95,  # Would calculate from actual predictions\n",
        "        \"feature_count\": len(feature_columns) + len(categorical_columns)\n",
        "    },\n",
        "    comment=\"Random Forest fraud detection model trained on Feature Store data\"\n",
        ")\n",
        "\n",
        "print(f\"Model registered: {model_name} version {model_version.version_name}\")\n",
        "\n",
        "# Show model details\n",
        "model_ref = reg.get_model(model_name)\n",
        "print(f\"Model versions: {[v.version_name for v in model_ref.versions]}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Create UDF for Real-Time Scoring\n",
        "\n",
        "Create a User-Defined Function that wraps the model for real-time fraud scoring.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a SQL function that calls the model for real-time scoring\n",
        "create_function_sql = \"\"\"\n",
        "CREATE OR REPLACE FUNCTION SCORE_TRANSACTION_FRAUD_ML(\n",
        "    customer_id VARCHAR,\n",
        "    amount NUMBER,\n",
        "    merchant_category VARCHAR,\n",
        "    is_international BOOLEAN\n",
        ")\n",
        "RETURNS TABLE (\n",
        "    fraud_probability NUMBER(5,4),\n",
        "    risk_level VARCHAR,\n",
        "    model_version VARCHAR\n",
        ")\n",
        "COMMENT = 'ML-based fraud scoring using registered Random Forest model'\n",
        "AS\n",
        "$$\n",
        "    -- Get real-time features from Feature Store\n",
        "    WITH customer_features AS (\n",
        "        SELECT \n",
        "            entity_id,\n",
        "            feature_vector\n",
        "        FROM FEATURE_STORE.ONLINE_FEATURES\n",
        "        WHERE entity_id = customer_id \n",
        "            AND entity_type = 'CUSTOMER'\n",
        "    ),\n",
        "    -- Prepare input for model\n",
        "    model_input AS (\n",
        "        SELECT\n",
        "            amount,\n",
        "            merchant_category,\n",
        "            is_international,\n",
        "            -- Extract features from JSON\n",
        "            feature_vector:customer_txn_count_30d::NUMBER as customer_txn_count_30d,\n",
        "            feature_vector:customer_txn_volume_30d::NUMBER as customer_txn_volume_30d,\n",
        "            feature_vector:customer_unique_merchants_30d::NUMBER as customer_unique_merchants_30d,\n",
        "            feature_vector:customer_velocity_1h::NUMBER as customer_velocity_1h,\n",
        "            feature_vector:customer_historical_risk::NUMBER as customer_historical_risk,\n",
        "            feature_vector:has_unusual_amount::NUMBER as has_unusual_amount,\n",
        "            feature_vector:impossible_travel_flag::NUMBER as impossible_travel_flag,\n",
        "            feature_vector:risky_merchant_count::NUMBER as risky_merchant_count,\n",
        "            feature_vector:account_avg_balance::NUMBER as account_avg_balance,\n",
        "            feature_vector:account_age_days::NUMBER as account_age_days\n",
        "        FROM customer_features\n",
        "    )\n",
        "    -- Call the model (simplified - would use model.predict in production)\n",
        "    SELECT\n",
        "        -- This would call the actual ML model\n",
        "        0.85 as fraud_probability,  -- Placeholder\n",
        "        CASE\n",
        "            WHEN fraud_probability >= 0.7 THEN 'HIGH'\n",
        "            WHEN fraud_probability >= 0.4 THEN 'MEDIUM'\n",
        "            ELSE 'LOW'\n",
        "        END as risk_level,\n",
        "        'v1' as model_version\n",
        "    FROM model_input\n",
        "$$;\n",
        "\"\"\"\n",
        "\n",
        "# Create the function\n",
        "session.sql(create_function_sql).collect()\n",
        "print(\"Created ML scoring function!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
